{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 23473,
     "status": "ok",
     "timestamp": 1527660021664,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "0ngCQdOD-fJ6",
    "outputId": "21c0c8e8-7193-4eef-e2f3-0449fe88a71f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
      "··········\n",
      "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
      "Please enter the verification code: Access token retrieved correctly.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from oauth2client.client import GoogleCredentials\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "import getpass\n",
    "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9GoHjm55-e6L"
   },
   "outputs": [],
   "source": [
    "!mkdir -p drive\n",
    "!google-drive-ocamlfuse drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 11560,
     "status": "ok",
     "timestamp": 1527660724120,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "80d3dD0G9g-N",
    "outputId": "f9c4838e-02b9-4ad0-c03e-80e95a2fc633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 22.6MB 1.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
      "Collecting smart-open>=1.2.1 (from gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/69/c92661a333f733510628f28b8282698b62cdead37291c8491f3271677c02/smart_open-1.5.7.tar.gz\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.3)\n",
      "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 9.1MB/s \n",
      "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/61/e3/79e80d130ee3dfbb576bd0adb1544ea27d14bfb7bdbaac415c73abc92385/boto3-1.7.29-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 10.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
      "Collecting botocore<1.11.0,>=1.10.29 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/f7/b2bd70e45a6efb008c9995d895ab00ef54cf2af35a84fc16625e020455b1/botocore-1.10.29-py2.py3-none-any.whl (4.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.3MB 6.8MB/s \n",
      "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 19.4MB/s \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.29->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
      "Collecting docutils>=0.10 (from botocore<1.11.0,>=1.10.29->boto3->smart-open>=1.2.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 22.4MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/b1/9e/7d/bb3d3b55c597e72617140a0638c06382a5f17283881eae163e\n",
      "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
      "Successfully built smart-open bz2file\n",
      "Installing collected packages: boto, bz2file, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.48.0 boto3-1.7.29 botocore-1.10.29 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.5.7\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "194qC08D_5I6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/macos/Library/Python/3.6/lib/python/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "ZW_RoDWY9k2i"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Users/macos/Desktop/School/20172/Project 2/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1527660882349,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "v2mV49-Z9k5J",
    "outputId": "3d9b0d05-2fee-43dc-db38-21a63d34c907"
   },
   "outputs": [],
   "source": [
    "vocab = model.wv.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "aFgxNnqgupWS"
   },
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    marks = ['.', ',', '\\n', '?', '!', '-', '(', ')', '/']\n",
    "    for mark in marks:\n",
    "        sentence = sentence.replace(mark, '')\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "gq2y5PuUtX57"
   },
   "outputs": [],
   "source": [
    "def get_lines_from_file(file_path):\n",
    "    file  = open(file_path, 'r')\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = preprocess_sentence(lines[i])\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "QKeZAwjQyOUX"
   },
   "outputs": [],
   "source": [
    "def get_sentence_vector(sentence):\n",
    "    sentence_vector = []\n",
    "    tokens = set(sentence.split(' '))\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "           sentence_vector.append(model[token])\n",
    "    return sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pozSCnjnphjB"
   },
   "outputs": [],
   "source": [
    "def get_sentence_vector_with_array(tokens):\n",
    "    for token in tokens:\n",
    "        if token in vocab:\n",
    "            sentence_vector.append(model[token])\n",
    "    return sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "bYpLY6Qr0vmr"
   },
   "outputs": [],
   "source": [
    "def get_train_data(file):\n",
    "    train_data = []\n",
    "    lines = get_lines_from_file(file)\n",
    "    for line in lines:\n",
    "        train_data.append(get_sentence_vector(line))\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Ub2K5FPE9k76"
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"rnn\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "9B6dZYJc9lBQ"
   },
   "outputs": [],
   "source": [
    "N_INPUTS = 300\n",
    "MAX_LENGTH = 100\n",
    "CONTEXT_SIZE = 5\n",
    "N_UNITS = 1024\n",
    "N_CLASSES = 300\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Yv0qZKFq-8un"
   },
   "outputs": [],
   "source": [
    "# in deep feedforward neural network, moi cau phai dua ve dang [-1, CONTEXT_SIZE * 2 * N_INPUTS]\n",
    "# -1 o day tuy thuoc vao do dai cua cau\n",
    "# chung ta can phai xu ly du lieu dau vao dua ve dang nay\n",
    "def get_data_for_feedforward(train_data):\n",
    "    X = []\n",
    "    y = []\n",
    "    for sentence_vector in train_data:\n",
    "        Xi = []\n",
    "        yi = []\n",
    "        #append CONTEXT_SIZE zeros vector in the head and in the tail of orginial vector\n",
    "        new_sentence_vector = np.array(sentence_vector)\n",
    "        context_vector = np.zeros(shape=[CONTEXT_SIZE, N_INPUTS])\n",
    "#         print(np.shape(context_vector))\n",
    "#         print(np.shape(new_sentence_vector))\n",
    "        new_sentence_vector = np.concatenate((new_sentence_vector, context_vector), axis=0)\n",
    "        new_sentence_vector = np.concatenate((context_vector, new_sentence_vector), axis=0)\n",
    "                \n",
    "        for i in range(CONTEXT_SIZE, np.shape(sentence_vector)[0] + 5):\n",
    "            left = np.array(new_sentence_vector[i - CONTEXT_SIZE: i]).reshape(-1)\n",
    "            right = np.array(new_sentence_vector[i + 1 : i + 1 + CONTEXT_SIZE]).reshape(-1)\n",
    "            x = np.concatenate((left, right), axis=0)\n",
    "            Xi.append(x)\n",
    "            yi.append(new_sentence_vector[i])\n",
    "            \n",
    "        X.append(np.array(Xi))\n",
    "        y.append(np.array(yi))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 4775,
     "status": "ok",
     "timestamp": 1527660896331,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "A2jlLWABuRvC",
    "outputId": "6ba252a1-43c9-4f2b-898e-b2cb7852cb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 17, 300)\n"
     ]
    }
   ],
   "source": [
    "path = '/Users/macos/Desktop/School/20172/Project 2/training_sentence.txt'\n",
    "train_data = get_train_data(path)\n",
    "# test_path = '/Users/macos/Desktop/School/20172/Project 2/test_sentence.txt'\n",
    "test_path = '/Users/macos/Desktop/School/20172/Project 2/test/test_result.txt'\n",
    "test_data = get_train_data(test_path)\n",
    "print(np.shape(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 737,
     "status": "ok",
     "timestamp": 1527660897315,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "0LJOxP90ibgo",
    "outputId": "0cfa0432-ca91-416e-bcf5-d2846f236367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(172,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "cSHSriUVBmbv"
   },
   "outputs": [],
   "source": [
    "train_x, train_y = get_data_for_feedforward(train_data)\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "test_x, test_y = get_data_for_feedforward(test_data)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 819,
     "status": "ok",
     "timestamp": 1527660902366,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "P6TqaxJJeipQ",
    "outputId": "2baf435b-71db-4db7-a5d7-3604fdb586c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 3000)\n"
     ]
    }
   ],
   "source": [
    "print(train_x[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "hfghukzbHGNN"
   },
   "outputs": [],
   "source": [
    "def get_batch(i):\n",
    "    return train_x[i], train_y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "II6XFwB_JMZk"
   },
   "outputs": [],
   "source": [
    "def shuffle(X, y):\n",
    "    a = [i for i in range(np.shape(X)[0])]\n",
    "    np.random.shuffle(a)\n",
    " \n",
    "    return X[a], y[a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JgZka1iO9ZdX"
   },
   "outputs": [],
   "source": [
    "def squared_error(a, b):\n",
    "    return tf.reduce_mean(tf.square(a - b), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "pFKmddLlFwS9"
   },
   "outputs": [],
   "source": [
    "def get_max_index(arr):\n",
    "    arr = np.reshape(arr, newshape=[-1, 4])\n",
    "    m = np.max(arr, axis=1, keepdims=True)\n",
    "    one_hot = arr // m\n",
    "    result = np.argmax(one_hot, axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "W4a-mJ3zhqFb"
   },
   "outputs": [],
   "source": [
    "def tf_get_max_index(arr):\n",
    "    arr = tf.reshape(arr, shape=[-1, 4])\n",
    "    m = tf.reduce_max(arr, axis=1, keepdims=True)\n",
    "    one_hot = arr // m\n",
    "    result = tf.argmax(one_hot, axis=1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 1081,
     "status": "ok",
     "timestamp": 1527660908659,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "L4ZuyNds9lEI",
    "outputId": "f1453e93-720c-4c7b-9713-9201e79304f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mean:0\", shape=(?,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "# mainly use to predict by using pretrained language model\n",
    "X = tf.placeholder(tf.float32, shape=[None, CONTEXT_SIZE * 2 * N_INPUTS], name='X')\n",
    "y = tf.placeholder(tf.float32, shape=[None, N_CLASSES], name='y')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, N_UNITS, activation=tf.nn.relu, name='hidden1')\n",
    "hidden2 = tf.layers.dense(hidden1, N_UNITS, activation=tf.nn.relu, name='hidden2')\n",
    "\n",
    "prediction = tf.layers.dense(hidden2, N_CLASSES)\n",
    "\n",
    "# khong dung soft max o day\n",
    "\n",
    "loss = tf.losses.mean_squared_error(y, prediction)\n",
    "# get loss in test\n",
    "loss_list = squared_error(y, prediction)\n",
    "print(loss_list)\n",
    "# result = tf_get_max_index(loss_list)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 881
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 41646,
     "status": "ok",
     "timestamp": 1527661678040,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "ckkqrlcf9lHC",
    "outputId": "94e9f23d-2e99-4d8c-8ada-0b67fceb2844"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/macos/Desktop/School/20172/Project 2/model/bow/model_bow.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/macos/Desktop/School/20172/Project 2/model/bow/model_bow.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    arr_test_loss = []\n",
    "#     for epoch in range(n_epochs):\n",
    "#         train_x, train_y = shuffle(train_x, train_y)\n",
    "#         for iteration in range(np.shape(train_x)[0]):\n",
    "#             #all vector in a sentence are in a batch, may make it differently by concatenating all sentences\n",
    "#             X_batch, y_batch = get_batch(iteration)\n",
    "            \n",
    "#             sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "#         train_loss_value = loss.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        \n",
    "#         print(epoch, \" Train loss value:\", train_loss_value)\n",
    "#     saver.save(sess, '/Users/macos/Desktop/School/20172/Project 2/model/bow/model_bow.ckpt')\n",
    "#     for i in range(np.shape(test_x)[0]):\n",
    "#         test_loss = loss.eval(feed_dict={X: test_x[i], y: test_y[i]})\n",
    "#         arr_test_loss.append(test_loss)\n",
    "    \n",
    "    saver.restore(sess, \"/Users/macos/Desktop/School/20172/Project 2/model/bow/model_bow.ckpt\")\n",
    "    for i in range(np.shape(test_x)[0]):\n",
    "        test_path = '/Users/macos/Desktop/School/20172/Project 2/test/test_result.txt'\n",
    "        test_data = get_train_data(test_path)\n",
    "        test_x, test_y = get_data_for_feedforward(test_data)\n",
    "        test_x = np.array(test_x)\n",
    "        test_y = np.array(test_y)\n",
    "        test_loss = loss.eval(feed_dict={X: test_x[i], y: test_y[i]})\n",
    "        arr_test_loss.append(test_loss)\n",
    "    dict = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "    new_arr = 1 / np.array(arr_test_loss)\n",
    "    predict_answer = np.array(get_max_index(new_arr))\n",
    "    print(dict[predict_answer[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B\n"
     ]
    }
   ],
   "source": [
    "dict = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}\n",
    "new_arr = 1 / np.array(arr_test_loss)\n",
    "predict_answer = np.array(get_max_index(new_arr))\n",
    "print(dict[predict_answer[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "hPi2a54R9lMw"
   },
   "outputs": [],
   "source": [
    "arr_ans = np.load('/Users/macos/Desktop/School/20172/Project 2/arr_ans.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 851,
     "status": "ok",
     "timestamp": 1527663882509,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "kfhaXRkBwagQ",
    "outputId": "81cb9a7a-87ee-48a6-f101-5260359cbb1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.259825327510917\n"
     ]
    }
   ],
   "source": [
    "new_arr = 1 / np.array(arr_test_loss)\n",
    "predict_answer = np.array(get_max_index(new_arr))\n",
    "# print(predict_answer)\n",
    "# for answer in predict_answer:\n",
    "#     print(dict[answer])\n",
    "print(np.sum(arr_ans == predict_answer) / np.shape(arr_ans)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 959,
     "status": "ok",
     "timestamp": 1527661392061,
     "user": {
      "displayName": "Nguyễn Thành Hậu",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "104616497617342567774"
     },
     "user_tz": -420
    },
    "id": "LU8oMMoo9lPp",
    "outputId": "531b8c62-545d-4bf8-cbb5-d50330d8302d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2663755458515284\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "l-3btUFq9lSs"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "eryTZSWX9lVp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "\bproject2_bow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
